{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Welcome to the Titanic Prediction Service!","text":"<p>This project fulfills a typical ML deployment pipeline, covering:</p> <ul> <li>Data processing and model training</li> <li>Building RESTful API endpoints (synchronous &amp; asynchronous)</li> <li>Containerization using Docker</li> <li>Clear Documentation</li> </ul>"},{"location":"#what-does-the-api-do","title":"What does the API do?","text":"<p>The API predicts the probability of survival for Titanic passengers based on:</p> <ul> <li>Passenger class (<code>Pclass</code>)</li> <li>Sex (<code>Sex</code>)</li> <li>Age (<code>Age</code>)</li> <li>Ticket fare (<code>Fare</code>)</li> </ul> <p>It offers both:</p> <ul> <li>Synchronous prediction (instant response)</li> <li>Asynchronous prediction (background processing using job IDs to retrieve results)</li> </ul>"},{"location":"#project-layout","title":"Project layout","text":"<pre><code>\u251c\u2500\u2500 app/                 # FastAPI app and model logic\n    \u251c\u2500\u2500 main.py          # FastAPI app with sync/async endpoints\n    \u251c\u2500\u2500 model.pkl        # Trained LightGBM model\n    \u2514\u2500\u2500 lgbm_model.py    # Model\n\u251c\u2500\u2500 docs/             # MkDocs documentation\n\u251c\u2500\u2500 pages/            # Streamlit app pages\n\u251c\u2500\u2500 data/             # Training data\n\u251c\u2500\u2500 Dockerfile        # Container build instructions\n\u251c\u2500\u2500 requirements.txt  # Dependencies\n\u2514\u2500\u2500 mkdocs.yml        # MkDocs configuration\n</code></pre>"},{"location":"api_endpoints/","title":"API Endpoints","text":"<p>This page explains the different Endpoints offered by the API for predicting the survival probability of Titanic  passengers using a trained LightGBM model.</p> <p>The two prediction modes are:</p> <ul> <li>Synchronous \u2014 Returns the result immediately after request</li> <li>Asynchronous \u2014 Runs in the background and allows result retrieving via a unique job ID</li> </ul> <p>Both endpoints accept the same input data format.</p>"},{"location":"api_endpoints/#input-format","title":"Input Format","text":"<p>All prediction requests have to send a JSON object with the following structure:</p> JSON <pre><code>{\n  \"Pclass\": 3,\n  \"Sex\": 0,\n  \"Age\": 22,\n  \"Fare\": 15\n}\n</code></pre> Field Type Description Constraints <code>Pclass</code> int Passenger class (1, 2, or 3) \u2265 1, \u2264 3 <code>Sex</code> int Gender (0 = male, 1 = female) \u2208 {0, 1} <code>Age</code> float Passenger's age \u2265 0 <code>Fare</code> float Ticket fare \u2265 0"},{"location":"api_endpoints/#synchronous-endpoint","title":"Synchronous Endpoint","text":""},{"location":"api_endpoints/#endpoint","title":"Endpoint","text":"<p>POST <code>/titanic_sync</code></p> <p>This endpoint returns the survival probability immediately after processing the input.</p>"},{"location":"api_endpoints/#example-response","title":"Example Response:","text":"JSON <pre><code>{\n  \"survival_probability\": 0.8676121599174949\n}\n</code></pre> <p>Note</p> <ul> <li>The model is loaded once when the API starts and reused for all incoming requests</li> </ul>"},{"location":"api_endpoints/#asynchronous-endpoint","title":"Asynchronous Endpoint","text":"<p>The asynchronous workflow consists of two steps:</p>"},{"location":"api_endpoints/#step-1-submit-a-job","title":"Step 1: Submit a Job","text":"<p>POST <code>/titanic_async</code></p>"},{"location":"api_endpoints/#example-response_1","title":"Example Response:","text":"JSON <pre><code>{\n  \"job_id\": \"job-1743685729\"\n}\n</code></pre> <p>You will receive a <code>job_id</code> which can be used to retrieve the result later.</p>"},{"location":"api_endpoints/#step-2-retrieve-the-result","title":"Step 2: Retrieve the Result","text":"<p>GET <code>/titanic_async/{job_id}</code></p>"},{"location":"api_endpoints/#possible-responses","title":"Possible Responses:","text":"<p>If still processing:</p> JSON <pre><code>{\n  \"status\": \"Processing\"\n}\n</code></pre> <p>If completed:</p> JSON <pre><code>{\n  \"status\": \"Done\",\n  \"survival_probability\": 0.8676121599174949\n}\n</code></pre> <p>Note</p> <ul> <li>All jobs are tracked in memory using a dictionary. Memory is deleted when API is shut down.</li> <li>Job IDs are timestamp-based (e.g., <code>job-1743685729</code>)</li> </ul>"},{"location":"containerization/","title":"Containerization","text":"<p>This project is fully containerized using Docker, allowing to run the Titanic Prediction API in a consistent environment, independent of any host system. </p>"},{"location":"containerization/#why-docker","title":"Why Docker?","text":"<p>Docker was chosen because it ensures that the application runs the same way on every machine, with:</p> <ul> <li>All dependencies included</li> <li>No need for manual setup</li> <li>Easy deployment to cloud platforms</li> </ul>"},{"location":"containerization/#dockerfile","title":"Dockerfile","text":"<p>The root of the project contains a <code>Dockerfile</code> that builds the FastAPI app with all dependencies:</p> Dockerfile <pre><code>FROM python:3.10\n\nWORKDIR /app\n\nCOPY . .\n\nRUN pip install --no-cache-dir -r requirements.txt\n\nCMD [   \"uvicorn\",              \\\n        \"app.main:app\",         \\\n        \"--host\", \"0.0.0.0\",    \\\n        \"--port\", \"8000\"        \\\n    ]\n</code></pre>"},{"location":"containerization/#build-the-docker-image","title":"Build the Docker Image","text":"<p>From the root of the project:</p> Bash <pre><code>docker build -t titanic-api .\n</code></pre>"},{"location":"containerization/#run-the-docker-container","title":"Run the Docker Container","text":"Bash <pre><code>docker run -p 8000:8000 titanic-api\n</code></pre> <p>Then open the browser and visit:</p> Bash <pre><code>http://localhost:8000/docs\n</code></pre>"},{"location":"containerization/#run-in-background-detached-mode","title":"Run in Background (Detached Mode)","text":"<p>To run the container in the background:</p> Bash <pre><code>docker run -d -p 8000:8000 --name titanic-api-container titanic-api\n</code></pre> <p>To stop it:</p> Bash <pre><code>docker stop titanic-api-container\n</code></pre>"},{"location":"model_building/","title":"Model Building","text":"<p>This page explains how the LightGBM model was trained for the Titanic survival prediction task.</p>"},{"location":"model_building/#dataset","title":"Dataset","text":"<p>The model is trained on the classic Titanic dataset,  which contains information about passengers from the Titanic and whether they survived or not.</p> <p>Here is a small sample of the dataset:</p> <p></p>"},{"location":"model_building/#features-used-for-training","title":"Features used for training","text":"<ul> <li><code>Pclass</code> \u2013 Passenger class (1 = first, 2 = second, 3 = third)</li> <li><code>Sex</code> \u2013 Gender (where 0 = male, 1 = female)</li> <li><code>Age</code> \u2013 Passenger's age in years</li> <li><code>Fare</code> \u2013 Ticket fare</li> </ul>"},{"location":"model_building/#target","title":"Target","text":""},{"location":"model_building/#target-during-training","title":"Target during training","text":"<ul> <li><code>Survived</code> \u2013 Survival status (0 = No, 1 = Yes)</li> </ul>"},{"location":"model_building/#target-predicted-by-the-model","title":"Target predicted by the model","text":"<ul> <li><code>Survival probability</code> \u2013 Probability value (0 to 1)'</li> </ul>"},{"location":"model_building/#preprocessing","title":"Preprocessing","text":"<p>The preprocessing steps include:</p> <ul> <li>Converted <code>Sex</code> from string to integer (<code>male</code> \u2192 <code>0</code>, <code>female</code> \u2192 <code>1</code>)</li> <li>Removed rows with missing values in selected columns</li> </ul>"},{"location":"model_building/#model-training","title":"Model Training","text":"<p>This model is trained on selected Titanic features, using `LightGBM classifier, and later used in a FastAPI app for real-time prediction.</p> Python <pre><code>from lightgbm import LGBMClassifier\n\nmodel = LGBMClassifier()\nmodel.fit(X_train, y_train)\n</code></pre>"},{"location":"model_building/#saving-and-loading-the-model","title":"Saving and Loading the Model","text":"<p>To reuse the trained model in the API, it is serialized and saved as a pickle file to disk using the  <code>joblib</code> library:</p>"},{"location":"model_building/#save-the-model","title":"Save the Model","text":"Python <pre><code>import joblib\n\njoblib.dump(model, 'model.pkl')\n</code></pre>"},{"location":"model_building/#load-the-model","title":"Load the Model","text":"<p>Once saved, the model can be loaded in the FastAPI application like this:</p> Python <pre><code>import joblib\n\nmodel = joblib.load('model.pkl')\n</code></pre> <p>This allows the API to use the trained model for making predictions without needing to retrain it each time.</p>"},{"location":"run/","title":"How to Run the Titanic Prediction API","text":"<p>This guide explains how to run the Titanic Prediction API using either a local Python environment or Docker. You can then test both the synchronous (<code>/titanic_sync</code>) and asynchronous (<code>/titanic_async</code>) endpoints using the Swagger UI.</p>"},{"location":"run/#option-1-run-with-docker","title":"Option 1: Run with Docker","text":""},{"location":"run/#1-clone-the-repository","title":"1. Clone the repository","text":"<pre><code>git clone https://github.com/rcroegaert/titanic-api.git\ncd titanic-api\n</code></pre>"},{"location":"run/#2-build-the-docker-image","title":"2. Build the Docker image","text":"<pre><code>docker build -t titanic-api .\n</code></pre>"},{"location":"run/#3-run-the-container","title":"3. Run the container","text":"<pre><code>docker run -p 8000:8000 titanic-api\n</code></pre>"},{"location":"run/#4-open-your-browser","title":"4. Open your browser","text":"<p>Navigate to: <pre><code>http://localhost:8000/docs\n</code></pre></p> <p>This opens the interactive Swagger UI.</p>"},{"location":"run/#option-2-run-locally-with-python","title":"Option 2: Run Locally with Python","text":""},{"location":"run/#1-clone-the-repository_1","title":"1. Clone the repository","text":"<pre><code>git clone https://github.com/your-username/titanic-api.git\ncd titanic-api\n</code></pre>"},{"location":"run/#2-create-a-virtual-environment","title":"2. Create a virtual environment","text":"<pre><code>python3 -m venv /path/to/new/virtual/environment\n\nsource .venv/bin/activate\n</code></pre>"},{"location":"run/#3-install-dependencies","title":"3. Install dependencies","text":"<pre><code>pip install -r requirements.txt\n</code></pre>"},{"location":"run/#4-start-the-fastapi-app","title":"4. Start the FastAPI app","text":"<pre><code>uvicorn app.main:app --reload\n</code></pre>"},{"location":"run/#5-open-your-browser","title":"5. Open your browser","text":"<p>Navigate to: <pre><code>http://localhost:8000/docs\n</code></pre></p>"}]}